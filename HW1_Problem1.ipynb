{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1_Problem1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EnterTheBeginning/Machine-Learning/blob/master/HW1_Problem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "CEghsswc1JiU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-Pl3BgX1jJw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing Data\n"
      ]
    },
    {
      "metadata": {
        "id": "Ef4PxUoo1fb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ba7de3a-e146-4b69-d10e-05424144d274"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train_original, y_train_original), (X_test_original, y_test_original) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "pNZtsqhI1WBN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train_original.reshape((60000, 28 * 28))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "\n",
        "X_test = X_test_original.reshape((10000, 28 * 28))\n",
        "X_test = X_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "di3W4of2qd-A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train, y_test = y_train_original.reshape(60000,1),y_test_original.reshape(10000,1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4rKMQCnRrQCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Lucky number 7:"
      ]
    },
    {
      "metadata": {
        "id": "F-VlCj8Us0DN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Classifer for number 7.  Anything except 7 is Zero and If y == 7 we have output of 1\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "pj2qOVxYoyyc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y1_train = np.zeros(y_train.shape)\n",
        "y1_train[np.where(y_train == 7.0)[0]] = 1\n",
        "y_train = y1_train\n",
        "\n",
        "y1_test = np.zeros(y_test.shape)\n",
        "y1_test[np.where(y_test == 7.0)[0]] = 1\n",
        "y_test = y1_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPrt0B0RdkiN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have input and output ready   \n",
        "Lets start building the first layer"
      ]
    },
    {
      "metadata": {
        "id": "7igJTn7qeYIE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Logistic regression with mean squared error loss.\n",
        "\n",
        "1.   Weights\n",
        "2.   Bias\n",
        "3. Activation\n",
        "4. Input X   \n",
        "n = Number of Features which is 784   \n",
        "m = Number of samples which in training set is 60000\n"
      ]
    },
    {
      "metadata": {
        "id": "qbIDf13AupXD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "np.random.seed(47)\n",
        "#W = np.random.rand(X_train.shape[1]).reshape(X_train.shape[1],1)\n",
        "W = np.zeros((X_train.shape[1], 1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r3Z81BUkhj2n",
        "colab_type": "code",
        "outputId": "79fd677e-fa1a-4c9b-abd2-b62ad69c2b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "W.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "PUugUn0flt7U",
        "colab_type": "code",
        "outputId": "edfd572a-72c7-4f24-9997-57f1eced657f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "b = np.zeros((1,1))\n",
        "b.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "eOO18U4-f07L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Sigmoid(z):\n",
        "    arg1 = 1 / (1 + np.exp(-z))\n",
        "    return arg1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RBsoF0VikKYW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Mean Squared Error (MSE):\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UfVHgu9qHDbH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MSE:\n",
        "  \n",
        "  #class constructor\n",
        "  #In order to save W for other methods such as prediction\n",
        "  def __init__(self,W,b):\n",
        "    self.W = np.zeros((X_train.shape[1],1))\n",
        "    self.b = np.zeros((1,1))\n",
        "  \n",
        "    #Derivative of Loss \n",
        "  def derMSELoss(self,A,y):\n",
        "    arg1 = A - y\n",
        "    return arg1\n",
        "  \n",
        "    #Derivative of Sigmoid method  \n",
        "  def derSigmoid(self,A):\n",
        "      arg1 = A*(1-A)\n",
        "      return arg1\n",
        "    \n",
        "    #Mean Squared Error method   \n",
        "  def MSELoss(self,X, y,W,b):\n",
        "      arg1 = (((Sigmoid(X.dot(W) + b)-y)**2)/2).mean()\n",
        "      return arg1\n",
        "   \n",
        "    #Training weights and Biases\n",
        "  def train(self, X, y,lr=0.01 , batch=128 , epochs = 1):\n",
        "    m=60000\n",
        "\n",
        "    history={\"Loss\":[]}\n",
        "\n",
        "    for i in range(epochs):\n",
        "      for e in range(0,m,batch):\n",
        "        X1= X[e:e+batch]\n",
        "        y1= y[e:e+batch]\n",
        "        Z= X1.dot(self.W)+self.b\n",
        "        # Activation function\n",
        "        A = Sigmoid(Z)\n",
        "        # Loss update\n",
        "        Gradient= self.derMSELoss(A,y1)*(self.derSigmoid(A))\n",
        "        # Updating the weights\n",
        "        self.W= self.W - lr * np.dot(Gradient.T,X1).T/batch\n",
        "        # Updating the bias\n",
        "        self.b= self.b- lr*Gradient.mean()\n",
        "      history[\"Loss\"] += [self.MSELoss(X,y,self.W,self.b)]\n",
        "      #Show the last history \n",
        "      print(\" Loss: {}\\n\".format(history['Loss'][-1]))\n",
        "    print(\"Test accuracy : {} %\".format(100 - np.mean(np.abs(network.predict(X_test) - y_test))*100))  \n",
        "    return history\n",
        "    \n",
        "  \n",
        "  def predict(self,X):\n",
        "        m = X.shape[0]\n",
        "        #creating a prediction vector\n",
        "        Z= X.dot(self.W)+self.b\n",
        "        A = Sigmoid(Z)\n",
        "        y_prediction = np.zeros((1,m))\n",
        "        for i in range(A.shape[0]):\n",
        "          if( A[i]>= 0.5):\n",
        "            y_prediction[0,i] = 1\n",
        "          else:\n",
        "            y_prediction[0,i] = 0\n",
        "        return y_prediction\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hzSMPv85X60Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###The results shown for the detection of Digit 7:"
      ]
    },
    {
      "metadata": {
        "id": "q5ecUlQrMbwi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network = MSE(None,None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0EtTNcS7ItI_",
        "colab_type": "code",
        "outputId": "2bd8a3d7-888c-4977-b075-554e0afc2850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "results = network.train(X_train, y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Loss: 0.04319978968412678\n",
            "\n",
            "Test accuracy : 89.91 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pjvl2Q43wj1C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Visualization:"
      ]
    },
    {
      "metadata": {
        "id": "9uZxNofrwjb7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "8d49c1fb-b71b-43ee-a782-b9f6e42f6ab3"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "plt.plot(results['Loss'], label='Loss')\n",
        "# plt.plot(prediction,label='prediction',color = 'green')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Loss reduction per epoch')\n",
        "plt.ylabel('loss') \n",
        "plt.show()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEHCAYAAABfkmooAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2DWbpo01aolJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "63111d90-443b-4626-92a1-2474b1684f3c"
      },
      "cell_type": "code",
      "source": [
        "network.predict(X_test[:20])\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "g0tzzRTsVkVP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Loop for classification of all numbers\n"
      ]
    },
    {
      "metadata": {
        "id": "F6WAL_OMmaQz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reseting the labels"
      ]
    },
    {
      "metadata": {
        "id": "6vSZmZAHV3WI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "0b5c475c-dff4-4d62-b47f-33171cd4cee4"
      },
      "cell_type": "code",
      "source": [
        "numbers = np.arange(10)\n",
        "networks = []\n",
        "history = []\n",
        "for i in numbers:\n",
        "    print(\"______________________________________\")\n",
        "    print(\"Training Classifier for the Number: {} \".format(i))\n",
        "    y2_train = np.zeros(y_train_original.shape)\n",
        "    y2_train[np.where(y_train_original == i)[0]] = 1\n",
        "    y_train = y2_train\n",
        "    y_train = y_train.reshape(60000,1)\n",
        "    networks += [MSE(None,None)]\n",
        "    history += [networks[-1].train(X_train, y_train)]\n",
        "    \n",
        "    y2_test = np.zeros(y_test_original.shape)\n",
        "    y2_test[np.where(y_test_original == i)[0]] = 1\n",
        "    y_test = y2_test\n",
        "    y_test = y_test.reshape(10000,1)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "______________________________________\n",
            "Training Classifier for the Number: 0 \n",
            " Loss: 0.030129312476892323\n",
            "\n",
            "Test accuracy : 89.91 %\n",
            "______________________________________\n",
            "Training Classifier for the Number: 1 \n",
            " Loss: 0.02779257968299318\n",
            "\n",
            "Test accuracy : 90.2 %\n",
            "______________________________________\n",
            "Training Classifier for the Number: 2 \n",
            " Loss: 0.04216637457644036\n",
            "\n",
            "Test accuracy : 88.65 %\n",
            "______________________________________\n",
            "Training Classifier for the Number: 3 \n",
            " Loss: 0.04214579819978914\n",
            "\n",
            "Test accuracy : 89.68 %\n",
            "______________________________________\n",
            "Training Classifier for the Number: 4 \n",
            " Loss: 0.03824473588011028\n",
            "\n",
            "Test accuracy : 89.9 %\n",
            "______________________________________\n",
            "Training Classifier for the Number: 5 \n",
            " Loss: 0.03993786367790622\n",
            "\n",
            "Test accuracy : 90.18 %\n",
            "______________________________________\n",
            "Training Classifier for the Number: 6 \n",
            " Loss: 0.037978259013493804\n",
            "\n",
            "Test accuracy : 91.08 %\n",
            "______________________________________\n",
            "Training Classifier for the Number: 7 \n",
            " Loss: 0.0351297234929648\n",
            "\n",
            "Test accuracy : 90.42 %\n",
            "______________________________________\n",
            "Training Classifier for the Number: 8 \n",
            " Loss: 0.04746023955436256\n",
            "\n",
            "Test accuracy : 89.72 %\n",
            "______________________________________\n",
            "Training Classifier for the Number: 9 \n",
            " Loss: 0.04319978968412678\n",
            "\n",
            "Test accuracy : 90.26 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VJJVliDvLtRb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Takes a long time. This is the result for Only for 1 epoch"
      ]
    },
    {
      "metadata": {
        "id": "SNj4iUE2L3ov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}