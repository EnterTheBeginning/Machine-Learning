{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_89.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EnterTheBeginning/Machine-Learning/blob/master/HW2_WinnerModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "voN80VP4NR7x",
        "colab_type": "code",
        "outputId": "ad0755b9-bbb9-4dad-9b1f-b3b98af054a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from scipy.misc import toimage\n",
        "from keras.layers import Dense, Activation, Flatten,Conv2D,MaxPooling2D,Dropout, BatchNormalization\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import regularizers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "pwO-fucWTV_B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10 \n",
        "(X_train_original, y_train_original), (X_test_original, y_test_original) = cifar10.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RGrZ-tj_AFCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#OneHotEncoding\n",
        "y_train = np_utils.to_categorical(y_train_original,10)\n",
        "y_test = np_utils.to_categorical(y_test_original,10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "f0f80UqLnf7m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Normalize\n",
        "x_train = X_train_original.astype('float32')\n",
        "x_test = X_test_original.astype('float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-neRB32NVtb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        "weight_decay = 1e-4\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vxjhTvim9E2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-60MK67oNbnB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        " \n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
        "\n",
        "# model.summary()\n",
        " \n",
        "#data augmentation\n",
        "\n",
        " \n",
        "#training\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3iP4dCadopPH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8oWUq6ZsNegJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1530
        },
        "outputId": "fba38888-12aa-42c1-ed84-70bf1254f034"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=125,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test))\n",
        "#save to disk\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/125\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 1.8877 - acc: 0.4332 - val_loss: 1.3390 - val_acc: 0.5789\n",
            "Epoch 2/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 1.2795 - acc: 0.5900 - val_loss: 1.0017 - val_acc: 0.6875\n",
            "Epoch 3/125\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 1.0836 - acc: 0.6538 - val_loss: 1.0098 - val_acc: 0.6952\n",
            "Epoch 4/125\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.9818 - acc: 0.6894 - val_loss: 0.8940 - val_acc: 0.7305\n",
            "Epoch 5/125\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.9170 - acc: 0.7131 - val_loss: 0.8398 - val_acc: 0.7504\n",
            "Epoch 6/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.8635 - acc: 0.7365 - val_loss: 0.8024 - val_acc: 0.7672\n",
            "Epoch 7/125\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.8302 - acc: 0.7484 - val_loss: 0.7539 - val_acc: 0.7761\n",
            "Epoch 8/125\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.8021 - acc: 0.7614 - val_loss: 0.7900 - val_acc: 0.7754\n",
            "Epoch 9/125\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.7784 - acc: 0.7706 - val_loss: 0.8067 - val_acc: 0.7746\n",
            "Epoch 10/125\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.7605 - acc: 0.7764 - val_loss: 0.7103 - val_acc: 0.7973\n",
            "Epoch 11/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7428 - acc: 0.7858 - val_loss: 0.6629 - val_acc: 0.8175\n",
            "Epoch 12/125\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.7321 - acc: 0.7913 - val_loss: 0.6883 - val_acc: 0.8123\n",
            "Epoch 13/125\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.7219 - acc: 0.7933 - val_loss: 0.7520 - val_acc: 0.7863\n",
            "Epoch 14/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7044 - acc: 0.8012 - val_loss: 0.6772 - val_acc: 0.8159\n",
            "Epoch 15/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7005 - acc: 0.8037 - val_loss: 0.7294 - val_acc: 0.8019\n",
            "Epoch 16/125\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.6911 - acc: 0.8060 - val_loss: 0.6515 - val_acc: 0.8283\n",
            "Epoch 17/125\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.6850 - acc: 0.8088 - val_loss: 0.6614 - val_acc: 0.8253\n",
            "Epoch 18/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.6785 - acc: 0.8114 - val_loss: 0.6687 - val_acc: 0.8213\n",
            "Epoch 19/125\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.6720 - acc: 0.8147 - val_loss: 0.6616 - val_acc: 0.8221\n",
            "Epoch 20/125\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.6654 - acc: 0.8161 - val_loss: 0.7358 - val_acc: 0.8103\n",
            "Epoch 21/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.6641 - acc: 0.8185 - val_loss: 0.6006 - val_acc: 0.8454\n",
            "Epoch 22/125\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.6561 - acc: 0.8203 - val_loss: 0.7194 - val_acc: 0.8101\n",
            "Epoch 23/125\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.6516 - acc: 0.8227 - val_loss: 0.6268 - val_acc: 0.8369\n",
            "Epoch 24/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.6511 - acc: 0.8236 - val_loss: 0.7344 - val_acc: 0.8058\n",
            "Epoch 25/125\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.6417 - acc: 0.8281 - val_loss: 0.6455 - val_acc: 0.8328\n",
            "Epoch 26/125\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.6392 - acc: 0.8289 - val_loss: 0.5976 - val_acc: 0.8483\n",
            "Epoch 27/125\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.6381 - acc: 0.8288 - val_loss: 0.7418 - val_acc: 0.8037\n",
            "Epoch 28/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.6380 - acc: 0.8287 - val_loss: 0.6146 - val_acc: 0.8423\n",
            "Epoch 29/125\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.6299 - acc: 0.8326 - val_loss: 0.6404 - val_acc: 0.8353\n",
            "Epoch 30/125\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.6318 - acc: 0.8315 - val_loss: 0.6479 - val_acc: 0.8303\n",
            "Epoch 31/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.6293 - acc: 0.8334 - val_loss: 0.6320 - val_acc: 0.8381\n",
            "Epoch 32/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.6235 - acc: 0.8344 - val_loss: 0.6006 - val_acc: 0.8509\n",
            "Epoch 33/125\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.6218 - acc: 0.8372 - val_loss: 0.5787 - val_acc: 0.8540\n",
            "Epoch 34/125\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.6250 - acc: 0.8353 - val_loss: 0.5796 - val_acc: 0.8566\n",
            "Epoch 35/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.6221 - acc: 0.8375 - val_loss: 0.6470 - val_acc: 0.8341\n",
            "Epoch 36/125\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.6156 - acc: 0.8389 - val_loss: 0.6624 - val_acc: 0.8343\n",
            "Epoch 37/125\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.6151 - acc: 0.8389 - val_loss: 0.6864 - val_acc: 0.8217\n",
            "Epoch 38/125\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.6089 - acc: 0.8404 - val_loss: 0.6167 - val_acc: 0.8439\n",
            "Epoch 39/125\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.6108 - acc: 0.8388 - val_loss: 0.5849 - val_acc: 0.8519\n",
            "Epoch 40/125\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.6135 - acc: 0.8391 - val_loss: 0.6684 - val_acc: 0.8347\n",
            "Epoch 41/125\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.6081 - acc: 0.8409 - val_loss: 0.6906 - val_acc: 0.8243\n",
            "Epoch 42/125\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.6025 - acc: 0.8436 - val_loss: 0.6137 - val_acc: 0.8516\n",
            "Epoch 43/125\n",
            "114/781 [===>..........................] - ETA: 30s - loss: 0.6067 - acc: 0.8444"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8rcGNCeQsQHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "acc = model.history['acc']\n",
        "val_acc = model.history['val_acc']\n",
        "\n",
        "loss = model.history['loss']\n",
        "val_loss = model.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# training and validation accuracy\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# training and validation loss\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sUJY-I2cptDN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##K-fold"
      ]
    }
  ]
}